xlim = c(0, 20),
ylim = c(0, 0.5),
main = paste("n =", n),
xlab = "x"
)
curve(f_y(x,0.258), from = 0, to = 20, add = TRUE, lwd = 2)
curve(2 * dgamma(x, shape=2, scale=2), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
}
#samp
mle1 <- optimize(function(lam) negloglik(lam, q4_samp), interval = c(1e-6, 5))$minimum
mle1
## graphing just to see:
curve(f_y(x,mle1), from = 0, to = 20,ylim = c(0, 0.4),  lwd = 2)
curve(2 * dgamma(x, shape=2, scale=our_beta), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
## simulate 1000 random samples of size 100
lambda = mle1
beta = our_beta
C = 2
samples <- replicate(1000, new_rbiweight(100,lambda,beta,C), simplify = FALSE)
length(samples)
length(samples[[1]])
mle_estimates <- sapply(samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
se_hat <- sd(mle_estimates)
lower <- mle1 - 1.96 * se_hat
upper <- mle1 + 1.96 * se_hat
c(lower, upper)
qqnorm(mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(mle_estimates, col = "red", lwd = 2)
xgrid <- seq(1e-6, 20, length.out = 5000)
max(f_y(xgrid, 0.8) / dgamma(xgrid, shape = 2, scale = 0.7))
## trying to find a c value such that the dgamma curve is on top of the pdf
curve(f_y(x,0.8), from = 0, to = 20,ylim = c(0, 1), lwd = 2)
curve(1.7 * dgamma(x, shape=2, scale=0.7), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
lambda = 0.8
beta = 0.7
C = 1.7
## question 4 with lambda = 0.8:
q_6_sample <- new_rbiweight(100,lambda,beta,C)
q_6_min_lamda <- optimize(function(lam) negloglik(lam, q_6_sample), interval = c(1e-6, 5))$minimum
q6_100_samples <- replicate(1000, new_rbiweight(100,q_6_min_lamda,beta,C), simplify = FALSE)
q6_mle_estimates <- sapply(q6_100_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6_se_hat <- sd(q6_mle_estimates)
lower <- q_6_min_lamda - 1.96 * q6_se_hat
upper <- q_6_min_lamda + 1.96 * q6_se_hat
c(lower, upper)
qqnorm(q6_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6_mle_estimates, col = "red", lwd = 2)
q_6b_sample <- new_rbiweight(100,lambda,beta,C)
q_6b_min_lamda <- optimize(function(lam) negloglik(lam, q_6b_sample), interval = c(1e-6, 5))$minimum
q6b_300_samples <- replicate(1000, new_rbiweight(300,q_6b_min_lamda,beta,C), simplify = FALSE)
q6b_mle_estimates <- sapply(q6b_300_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6b_se_hat <- sd(q6b_mle_estimates)
lower <- q_6b_min_lamda - 1.96 * q6b_se_hat
upper <- q_6b_min_lamda + 1.96 * q6b_se_hat
c(lower, upper)
qqnorm(q6b_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6b_mle_estimates, col = "red", lwd = 2)
set.seed(123)
rbiweight <- function(n) {
u1 <- runif(1.5*n, -1, 1)
u2 <- runif(1.5*n, 0, 15/16)
x <- u1[u2 < 15/16*(1-u1^2)^2]
if (length(x) < n) {
return(c(x, rbiweight(n-length(x))))
} else {
return(x[1:n])
}
}
pdf <- function(x) {
y <- (15/16) * (1 - x^2)^2
y[abs(x) > 1] <- 0
y
}
sizes <- c(20, 50, 100, 200)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grid
for (n in sizes) {
samp <- rbiweight(n)
hist(
samp, prob = TRUE, breaks = "FD",
xlim = c(-1, 1),
ylim = c(0, 1.5),
main = paste("n =", n),
xlab = "x"
)
curve(pdf(x), from = -1, to = 1, add = TRUE, lwd = 2)
}
rbiweight <- function(n) {
u1 <- runif(1.5*n, 0, 5)
u2 <- runif(1.5*n, 0, 1/(1-exp(-5)))
x <- u1[u2 < 1/(1-exp(-5))*exp(-u1)]
if (length(x) < n) {
return(c(x, rbiweight(n-length(x))))
} else {
return(x[1:n])
}
}
pdf <- function(x) {
y <- 1/(1-exp(-5))*exp(-x)
y
}
sizes <- c(20, 50, 100, 200)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grid
for (n in sizes) {
samp <- rbiweight(n)
hist(
samp, prob = TRUE, breaks = "FD",
xlim = c(0, 5),
ylim = c(0, 1),
main = paste("n =", n),
xlab = "x"
)
curve(pdf(x), from = 0, to = 5, add = TRUE, lwd = 2)
}
f_y <- function(y,lam){
2*lam^2*y*exp(-2*lam*y) + 16*lam^3*y^2*exp(-4*lam*y)}
compute_lam <- function(y){
lam_vec <- c(0.1,0.2,0.3,0.4)
best_likelihood <- 0
best_lambda <- 0
for (value in lam_vec){
likelihood  <- prod(f_y(y,value))
if (likelihood > best_likelihood) {
best_likelihood <- likelihood
best_lambda <- value
}
}
return(best_lambda)
}
#1) y=2.3
y <- c(2.3)
lambda <- compute_lam(y)
lambda
#2) y=2.3,4.1
y <- c(2.3,4.1)
lambda <- compute_lam(y)
lambda
#3) y=2.3,4.1,3.2
y <- c(2.3,4.1,3.2)
lambda <- compute_lam(y)
lambda
negloglik <- function(lam, y) {
if (lam <= 0) return(Inf)   # enforce lambda > 0
-sum(log(f_y(y, lam)))
}
y1 <- c(2.3)
y2 <- c(2.3, 4.1)
y3 <- c(2.3, 4.1, 3.2)
mle1 <- optimize(function(lam) negloglik(lam, y1), interval = c(1e-6, 5))$minimum
mle2 <- optimize(function(lam) negloglik(lam, y2), interval = c(1e-6, 5))$minimum
mle3 <- optimize(function(lam) negloglik(lam, y3), interval = c(1e-6, 5))$minimum
mle1
mle2
mle3
lambda <- 0.258
new_rbiweight <- function(n, lam = 0.258, beta = 2, C = 2) {
u1 <- rgamma(ceiling(1.5*n), shape = 2, scale = beta)
u2 <- runif(ceiling(1.5*n), 0, C * dgamma(u1, shape = 2, scale = beta))
x <- u1[u2 < f_y(u1, lam)]
if (length(x) < n) {
return(c(x, new_rbiweight(n - length(x), lam, beta, C)))
} else {
return(x[1:n])
}
}
sizes <- c(100)
## graphing just to see:
for (n in sizes) {
q4_samp <- new_rbiweight(n,0.258,2,2)
hist(
q4_samp, prob = TRUE, breaks = "FD",
xlim = c(0, 20),
ylim = c(0, 0.5),
main = paste("n =", n),
xlab = "x"
)
curve(f_y(x,0.258), from = 0, to = 20, add = TRUE, lwd = 2)
curve(2 * dgamma(x, shape=2, scale=2), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
}
#samp
mle1 <- optimize(function(lam) negloglik(lam, q4_samp), interval = c(1e-6, 5))$minimum
mle1
## graphing just to see:
curve(f_y(x,mle1), from = 0, to = 20,ylim = c(0, 0.4),  lwd = 2)
curve(2 * dgamma(x, shape=2, scale=our_beta), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
## simulate 1000 random samples of size 100
lambda = mle1
beta = our_beta
C = 2
samples <- replicate(1000, new_rbiweight(100,lambda,beta,C), simplify = FALSE)
length(samples)
length(samples[[1]])
mle_estimates <- sapply(samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
se_hat <- sd(mle_estimates)
lower <- mle1 - 1.96 * se_hat
upper <- mle1 + 1.96 * se_hat
c(lower, upper)
qqnorm(mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(mle_estimates, col = "red", lwd = 2)
xgrid <- seq(1e-6, 20, length.out = 5000)
max(f_y(xgrid, 0.8) / dgamma(xgrid, shape = 2, scale = 0.7))
## trying to find a c value such that the dgamma curve is on top of the pdf
curve(f_y(x,0.8), from = 0, to = 20,ylim = c(0, 1), lwd = 2)
curve(1.7 * dgamma(x, shape=2, scale=0.7), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
lambda = 0.8
beta = 0.7
C = 1.7
## question 4 with lambda = 0.8:
q_6_sample <- new_rbiweight(100,lambda,beta,C)
q_6_min_lamda <- optimize(function(lam) negloglik(lam, q_6_sample), interval = c(1e-6, 5))$minimum
q6_100_samples <- replicate(1000, new_rbiweight(100,q_6_min_lamda,beta,C), simplify = FALSE)
q6_mle_estimates <- sapply(q6_100_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6_se_hat <- sd(q6_mle_estimates)
lower <- q_6_min_lamda - 1.96 * q6_se_hat
upper <- q_6_min_lamda + 1.96 * q6_se_hat
c(lower, upper)
qqnorm(q6_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6_mle_estimates, col = "red", lwd = 2)
q_6b_sample <- new_rbiweight(300,lambda,beta,C)
q_6b_min_lamda <- optimize(function(lam) negloglik(lam, q_6b_sample), interval = c(1e-6, 5))$minimum
q6b_300_samples <- replicate(1000, new_rbiweight(300,q_6b_min_lamda,beta,C), simplify = FALSE)
q6b_mle_estimates <- sapply(q6b_300_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6b_se_hat <- sd(q6b_mle_estimates)
lower <- q_6b_min_lamda - 1.96 * q6b_se_hat
upper <- q_6b_min_lamda + 1.96 * q6b_se_hat
c(lower, upper)
qqnorm(q6b_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6b_mle_estimates, col = "red", lwd = 2)
set.seed(123)
rbiweight <- function(n) {
u1 <- runif(1.5*n, -1, 1)
u2 <- runif(1.5*n, 0, 15/16)
x <- u1[u2 < 15/16*(1-u1^2)^2]
if (length(x) < n) {
return(c(x, rbiweight(n-length(x))))
} else {
return(x[1:n])
}
}
pdf <- function(x) {
y <- (15/16) * (1 - x^2)^2
y[abs(x) > 1] <- 0
y
}
sizes <- c(20, 50, 100, 200)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grid
for (n in sizes) {
samp <- rbiweight(n)
hist(
samp, prob = TRUE, breaks = "FD",
xlim = c(-1, 1),
ylim = c(0, 1.5),
main = paste("n =", n),
xlab = "x"
)
curve(pdf(x), from = -1, to = 1, add = TRUE, lwd = 2)
}
rbiweight <- function(n) {
u1 <- runif(1.5*n, 0, 5)
u2 <- runif(1.5*n, 0, 1/(1-exp(-5)))
x <- u1[u2 < 1/(1-exp(-5))*exp(-u1)]
if (length(x) < n) {
return(c(x, rbiweight(n-length(x))))
} else {
return(x[1:n])
}
}
pdf <- function(x) {
y <- 1/(1-exp(-5))*exp(-x)
y
}
sizes <- c(20, 50, 100, 200)
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))  # 2x2 grid
for (n in sizes) {
samp <- rbiweight(n)
hist(
samp, prob = TRUE, breaks = "FD",
xlim = c(0, 5),
ylim = c(0, 1),
main = paste("n =", n),
xlab = "x"
)
curve(pdf(x), from = 0, to = 5, add = TRUE, lwd = 2)
}
f_y <- function(y,lam){
2*lam^2*y*exp(-2*lam*y) + 16*lam^3*y^2*exp(-4*lam*y)}
compute_lam <- function(y){
lam_vec <- c(0.1,0.2,0.3,0.4)
best_likelihood <- 0
best_lambda <- 0
for (value in lam_vec){
likelihood  <- prod(f_y(y,value))
if (likelihood > best_likelihood) {
best_likelihood <- likelihood
best_lambda <- value
}
}
return(best_lambda)
}
#1) y=2.3
y <- c(2.3)
lambda <- compute_lam(y)
lambda
#2) y=2.3,4.1
y <- c(2.3,4.1)
lambda <- compute_lam(y)
lambda
#3) y=2.3,4.1,3.2
y <- c(2.3,4.1,3.2)
lambda <- compute_lam(y)
lambda
negloglik <- function(lam, y) {
if (lam <= 0) return(Inf)   # enforce lambda > 0
-sum(log(f_y(y, lam)))
}
y1 <- c(2.3)
y2 <- c(2.3, 4.1)
y3 <- c(2.3, 4.1, 3.2)
mle1 <- optimize(function(lam) negloglik(lam, y1), interval = c(1e-6, 5))$minimum
mle2 <- optimize(function(lam) negloglik(lam, y2), interval = c(1e-6, 5))$minimum
mle3 <- optimize(function(lam) negloglik(lam, y3), interval = c(1e-6, 5))$minimum
mle1
mle2
mle3
lambda <- 0.258
new_rbiweight <- function(n, lam = 0.258, beta = 2, C = 2) {
u1 <- rgamma(ceiling(1.5*n), shape = 2, scale = beta)
u2 <- runif(ceiling(1.5*n), 0, C * dgamma(u1, shape = 2, scale = beta))
x <- u1[u2 < f_y(u1, lam)]
if (length(x) < n) {
return(c(x, new_rbiweight(n - length(x), lam, beta, C)))
} else {
return(x[1:n])
}
}
sizes <- c(100)
## graphing just to see:
for (n in sizes) {
q4_samp <- new_rbiweight(n,0.258,2,2)
hist(
q4_samp, prob = TRUE, breaks = "FD",
xlim = c(0, 20),
ylim = c(0, 0.5),
main = paste("n =", n),
xlab = "x"
)
curve(f_y(x,0.258), from = 0, to = 20, add = TRUE, lwd = 2)
curve(2 * dgamma(x, shape=2, scale=2), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
}
#samp
mle1 <- optimize(function(lam) negloglik(lam, q4_samp), interval = c(1e-6, 5))$minimum
mle1
## graphing just to see:
curve(f_y(x,mle1), from = 0, to = 20,ylim = c(0, 0.4),  lwd = 2)
curve(2 * dgamma(x, shape=2, scale=2), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
## simulate 1000 random samples of size 100
lambda = mle1
beta = 2
C = 2
samples <- replicate(1000, new_rbiweight(100,lambda,beta,C), simplify = FALSE)
length(samples)
length(samples[[1]])
mle_estimates <- sapply(samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
se_hat <- sd(mle_estimates)
lower <- mle1 - 1.96 * se_hat
upper <- mle1 + 1.96 * se_hat
c(lower, upper)
qqnorm(mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(mle_estimates, col = "red", lwd = 2)
xgrid <- seq(1e-6, 20, length.out = 5000)
max(f_y(xgrid, 0.8) / dgamma(xgrid, shape = 2, scale = 0.7))
## trying to find a c value such that the dgamma curve is on top of the pdf
curve(f_y(x,0.8), from = 0, to = 20,ylim = c(0, 1), lwd = 2)
curve(1.7 * dgamma(x, shape=2, scale=0.7), from = 0, to = 20, add = TRUE, lwd = 2, col = "blue") ## i added this just to see if this is actually above the orginal function
lambda = 0.8
beta = 0.7
C = 1.7
## question 4 with lambda = 0.8:
q_6_sample <- new_rbiweight(100,lambda,beta,C)
q_6_min_lamda <- optimize(function(lam) negloglik(lam, q_6_sample), interval = c(1e-6, 5))$minimum
q6_100_samples <- replicate(1000, new_rbiweight(100,q_6_min_lamda,beta,C), simplify = FALSE)
q6_mle_estimates <- sapply(q6_100_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6_se_hat <- sd(q6_mle_estimates)
lower <- q_6_min_lamda - 1.96 * q6_se_hat
upper <- q_6_min_lamda + 1.96 * q6_se_hat
c(lower, upper)
qqnorm(q6_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6_mle_estimates, col = "red", lwd = 2)
q_6b_sample <- new_rbiweight(300,lambda,beta,C)
q_6b_min_lamda <- optimize(function(lam) negloglik(lam, q_6b_sample), interval = c(1e-6, 5))$minimum
q6b_300_samples <- replicate(1000, new_rbiweight(300,q_6b_min_lamda,beta,C), simplify = FALSE)
q6b_mle_estimates <- sapply(q6b_300_samples, function(sample) {
optimize(function(lam) negloglik(lam, sample),
interval = c(1e-6, 5))$minimum
})
q6b_se_hat <- sd(q6b_mle_estimates)
lower <- q_6b_min_lamda - 1.96 * q6b_se_hat
upper <- q_6b_min_lamda + 1.96 * q6b_se_hat
c(lower, upper)
qqnorm(q6b_mle_estimates, main = "Normal QQ-plot of 1000 MLEs")
qqline(q6b_mle_estimates, col = "red", lwd = 2)
L1 <- exp(rnorm(1000))
L2 <- exp(rnorm(1000))
L1 <- exp(rnorm(1000))
L2 <- exp(rnorm(1000))
x1 <- L1 + L2
x2 <- L1 - L2
cor(x1,x2)
plot(x1,x2)
set.seed(39133)
L1 <- exp(rnorm(1000))
L2 <- exp(rnorm(1000))
x1 <- L1 + L2
x2 <- L1 - L2
cor(x1,x2)
plot(x1,x2)
u <- runif(1000)
x <- (sqrt(1+8*u)-1)/2
hist(X, freq = FALSE)
x <- (sqrt(8*U+1) - 1)/2
hist(x, freq = FALSE)
set.seed(26636)
x <- arima.sim(
n = 200,
model = list(ar = -0.4, ma = 0.6),
sd = 1
)
x[200]
set.seed(26636)
x <- arima.sim(
n = 200,
model = list(ar = -0.4, ma = 0.6),
sd = 1
)
x[200]
set.seed(26636)
x <- arima.sim(
n = 200,
model = list(order = c(1,1,1), ar = -0.4, ma = 0.6),
sd = 1
)
x[200]
set.seed(123)
x <- arima.sim(
n = 100,
model = list(ma = -0.7),
sd = sqrt(2)
)
acf(x)
install.packages("DT")
library(DT)
DT::datatable(tbl, options = list(pageLength = 10))
suppressWarnings(devtools::load_all())
spec <- list(
query = "cancer",
max_records = 10,
phase = "Phase 2",
country = "Canada",
from_date = "2022-01-01",
to_date = "2023-01-01",
date_filter = "StartDate"
)
out <- trials_run_spec(spec)
str(out)
suppressWarnings(devtools::load_all())
spec <- list(
query = "cancer",
max_records = 10,
phase = "Phase 2",
country = "Canada",
from_date = "2022-01-01",
to_date = "2023-01-01",
date_filter = "StartDate"
)
out <- trials_run_spec(spec)
setwd("C:/Users/preet/Documents/DATA534/clinicaltrialsR")
devtools::load_all()
spec <- list(
query = "cancer",
max_records = 10,
phase = "Phase 2",
country = "Canada",
from_date = "2022-01-01",
to_date = "2023-01-01",
date_filter = "StartDate"
)
result <- trials_run_spec(spec)
extract_identificationModule(result$studies[[1]])
studies_to_table(result$studies, modules = "identificationModule")
